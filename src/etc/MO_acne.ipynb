{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCdXgzjtXguF",
        "outputId": "ad9973f4-55bd-40af-9977-f39eb91d9844"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/face.zip'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")"
      ],
      "metadata": {
        "id": "Y0HT0cDuX5Kw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj9_VmlPXLPz",
        "outputId": "3bd798d7-1c2e-43a8-efee-2556d53783c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64])\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "\n",
        "# Data Variables | Dataset from Kaggle\n",
        "train_data = \"/content/face/DATA/train/\"\n",
        "test_data = \"/content/face/DATA/testing/\"\n",
        "list_train = ['Acne', 'Rosacea', 'Normal']  # The category we want to train the Model with.\n",
        "\n",
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Перемещаем модель на GPU, если она доступна\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 3)\n",
        "model = model.to(device).eval()  # Перевод модели на устройство и перевод в режим eval\n",
        "\n",
        "# Извлечение слоя \"avgpool\" для извлечения признаков\n",
        "avgpool_layer = model.avgpool\n",
        "\n",
        "# Пример использования признаков\n",
        "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
        "features = avgpool_layer(model.conv1(input_tensor))  # Применение avgpool_layer к выходу conv1\n",
        "print((features.squeeze(2,3)).shape)  # Размерность признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VHaqtcw1fmcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, numpy as np, pandas as pd\n",
        "\n",
        "def data_gen(): # This module will scour through defined paths to find images & add them to our dictionary.\n",
        "    k = 0\n",
        "    # Dictionaries to store training & testing image paths and targets\n",
        "    train_dictionary = {\"img_path\": [], \"target\": []}\n",
        "    test_dictionary = {\"img_path\": [], \"target\": []}\n",
        "\n",
        "    for i in list_train:\n",
        "        path_disease_train = train_data + i\n",
        "        path_disease_test = test_data + i\n",
        "\n",
        "        image_list_train = os.listdir(path_disease_train)\n",
        "        image_list_test = os.listdir(path_disease_test)\n",
        "\n",
        "        for j in image_list_train:\n",
        "            img_path_train = path_disease_train + \"/\" + j\n",
        "            train_dictionary[\"img_path\"].append(img_path_train)\n",
        "            train_dictionary['target'].append(k)\n",
        "\n",
        "        for m in image_list_test:\n",
        "            img_path_test = path_disease_test + \"/\" + m\n",
        "            test_dictionary[\"img_path\"].append(img_path_test)\n",
        "            test_dictionary['target'].append(k)\n",
        "        k += 1\n",
        "\n",
        "    # Create a testing & training DataFrame from the test & train dictionary.\n",
        "    test_df = pd.DataFrame(test_dictionary)\n",
        "    train_df = pd.DataFrame(train_dictionary)\n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "dvwOSYA_bBRq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "import matplotlib.pyplot as plt, random\n",
        "from PIL import Image as PILImageHandler\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def load_data(input_size=(224, 224)):  # Function to load and preprocess the data\n",
        "    images = []\n",
        "    images2 = []\n",
        "    train_df, test_df = data_gen()\n",
        "\n",
        "    for i in train_df['img_path']:\n",
        "        img = cv2.imread(i)\n",
        "        img = cv2.resize(img, input_size)\n",
        "        images.append(img)\n",
        "    y_train = np.asarray(train_df['target'])\n",
        "    x_train = np.asarray(images)\n",
        "\n",
        "    for i in test_df['img_path']:\n",
        "        img = cv2.imread(i)\n",
        "        img = cv2.resize(img, input_size)\n",
        "        images2.append(img)\n",
        "    y_test = np.asarray(test_df['target'])\n",
        "    x_test = np.asarray(images2)\n",
        "\n",
        "    return x_train, x_test, y_train, y_test  # Return the preprocessed data\n",
        "\n",
        "x_train, x_test, y_train, y_test = load_data(input_size=(224, 224))  # Load and preprocess the data"
      ],
      "metadata": {
        "id": "F_dNU6Skb7Gq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def load_img(img_path):\n",
        "    # Загрузка изображения и предобработка\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    img = transform(img)\n",
        "    img = torch.unsqueeze(img, 0)  # Добавление размерности пакета (batch dimension)\n",
        "\n",
        "    # Перевод изображения на устройство\n",
        "    img = img.to(device)\n",
        "\n",
        "    # Применение модели и извлечение признаков\n",
        "    with torch.no_grad():\n",
        "        features = model(img)\n",
        "\n",
        "    # Извлечение признаков и преобразование в массив NumPy\n",
        "    features = features.squeeze().cpu().numpy()\n",
        "\n",
        "    return features\n",
        "\n",
        "img_path = \"/content/face/DATA/testing/Acne/12.jpg\"\n",
        "img_features = load_img(img_path)\n",
        "print(img_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16Pro4Y6fWgN",
        "outputId": "8027051f-1f58-441b-828c-65d210966dda"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# Определение класса для загрузки и предобработки данных\n",
        "class SkinDataset(Dataset):\n",
        "    def __init__(self, x, y, transform=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.x[idx]\n",
        "        label = self.y[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# Предобработка данных\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = SkinDataset(x_train, y_train, transform=transform)\n",
        "test_dataset = SkinDataset(x_test, y_test, transform=transform)\n",
        "\n",
        "# Загрузка данных с помощью DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Определение функции потерь и оптимизатора\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Инициализация переменной для хранения наилучшей точности и соответствующих весов модели\n",
        "best_accuracy = 0.0\n",
        "best_model_weights = None\n",
        "\n",
        "# Цикл обучения модели с выводом потери на каждой итерации\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Вывод потери на каждой итерации\n",
        "        if i % 100 == 0:  # выведите потерю каждые 100 итераций\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Подсчет и вывод средней потери на эпохе\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Оценка модели на тестовом наборе данных и сохранение модели с лучшими весами\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Рассчет точности на тестовом наборе данных\n",
        "        accuracy = correct / total\n",
        "        print(f\"Accuracy on test set: {100 * accuracy:.2f}%\")\n",
        "\n",
        "        # Сохранение модели с наилучшими весами\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model_weights = model.state_dict()\n",
        "\n",
        "# Сохранение модели с наилучшими весами\n",
        "torch.save(best_model_weights, 'best_model.pth')\n",
        "print(\"Best model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCRZAgZVh1JQ",
        "outputId": "8408b55e-cc5c-4b65-c2d5-d3c89698464c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.4890\n",
            "Accuracy on test set: 56.03%\n",
            "Epoch [2/20], Loss: 0.2028\n",
            "Accuracy on test set: 67.24%\n",
            "Epoch [3/20], Loss: 0.0980\n",
            "Accuracy on test set: 81.03%\n",
            "Epoch [4/20], Loss: 0.1397\n",
            "Accuracy on test set: 95.69%\n",
            "Epoch [5/20], Loss: 0.0879\n",
            "Accuracy on test set: 87.93%\n",
            "Epoch [6/20], Loss: 0.1004\n",
            "Accuracy on test set: 85.34%\n",
            "Epoch [7/20], Loss: 0.0578\n",
            "Accuracy on test set: 95.69%\n",
            "Epoch [8/20], Loss: 0.0351\n",
            "Accuracy on test set: 88.79%\n",
            "Epoch [9/20], Loss: 0.0201\n",
            "Accuracy on test set: 94.83%\n",
            "Epoch [10/20], Loss: 0.0108\n",
            "Accuracy on test set: 85.34%\n",
            "Epoch [11/20], Loss: 0.0158\n",
            "Accuracy on test set: 90.52%\n",
            "Epoch [12/20], Loss: 0.0317\n",
            "Accuracy on test set: 56.90%\n",
            "Epoch [13/20], Loss: 0.0921\n",
            "Accuracy on test set: 81.03%\n",
            "Epoch [14/20], Loss: 0.1943\n",
            "Accuracy on test set: 80.17%\n",
            "Epoch [15/20], Loss: 0.0844\n",
            "Accuracy on test set: 87.07%\n",
            "Epoch [16/20], Loss: 0.0599\n",
            "Accuracy on test set: 87.93%\n",
            "Epoch [17/20], Loss: 0.0621\n",
            "Accuracy on test set: 67.24%\n",
            "Epoch [18/20], Loss: 0.0310\n",
            "Accuracy on test set: 79.31%\n",
            "Epoch [19/20], Loss: 0.0306\n",
            "Accuracy on test set: 88.79%\n",
            "Epoch [20/20], Loss: 0.0183\n",
            "Accuracy on test set: 90.52%\n",
            "Best model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение весов наилучшей модели\n",
        "torch.save(best_model_weights, 'best_model_weights.pth')\n",
        "print(\"Best model weights saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6zIpLQ5lIUK",
        "outputId": "86d1a991-cf3c-4187-974e-3798a816c42c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model weights saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/best_model_weights.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Функция для загрузки и предобработки изображения лица\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image)\n",
        "    image = torch.unsqueeze(image, 0)\n",
        "    return image\n",
        "\n",
        "# Путь к изображению лица\n",
        "face_image_path = \"/content/1.jpg\"\n",
        "\n",
        "# Предобработка изображения\n",
        "face_image = preprocess_image(face_image_path)\n",
        "face_image = preprocess_image(face_image_path).to(device)\n",
        "\n",
        "\n",
        "# Передача изображения через модель для получения предсказаний\n",
        "with torch.no_grad():\n",
        "    outputs = model(face_image)\n",
        "\n",
        "# Получение предсказанных вероятностей для каждого класса\n",
        "probabilities = torch.softmax(outputs, dim=1)[0]\n",
        "class_names = ['Acne', 'Rosacea', 'Normal']  # Предположим, что это порядок классов\n",
        "\n",
        "# Вывод предсказаний\n",
        "for i, prob in enumerate(probabilities):\n",
        "    class_name = class_names[i]\n",
        "    print(f\"Probability of {class_name}: {prob.item()}\")\n",
        "\n",
        "# Пример анализа предсказаний и отображения результатов\n",
        "threshold = 0.5  # Порог вероятности для классификации\n",
        "if probabilities[0] > threshold:\n",
        "    print(\"Acne detected!\")\n",
        "    # Дополнительные действия для обработки обнаружения акне на изображении\n",
        "else:\n",
        "    print(\"No acne detected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAVk6FuFoMGF",
        "outputId": "b0284079-6cd8-496e-d61e-2bc61992fb13"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of Acne: 0.0006646826514042914\n",
            "Probability of Rosacea: 0.13390961289405823\n",
            "Probability of Normal: 0.8654256463050842\n",
            "No acne detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uuxVfysHjXgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdNTdJ7cjXeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSRchN8LjXbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVPnOYsljXZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WiIFjroTjXWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYkkFNTpjXUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ModNlHqgjXRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = str(input(\"Which Skin disease to compare with our model?\\n Acne, Rosacea or Eczema?: \"))\n",
        "img_number = str(input(\"Will you enter the number of the image or should it be random?\\n Filename: \"))\n",
        "\n",
        "base_path = \"face_data/DATA/train/\"+userInput+\"/\"\n",
        "\n",
        "if img_number.lower() == \"random\":\n",
        "    files = os.listdir(base_path)\n",
        "    file = [random.choice(files)]\n",
        "    final = base_path + f\"{file[0]}\"; print(final)\n",
        "    print(f\"The random file chosen is: {file}\\n The final path is: {final}\")\n",
        "\n",
        "else:\n",
        "    final = base_path + img_number + \".jpg\"\n",
        "    print(f\"The file chosen is: {img_number}\\n The final path is: {final}\")\n",
        "\n",
        "img_path = final\n",
        "# model.save('saved_model/skin_model')\n",
        "# model = load_model('saved_model/skin_model')\n",
        "img = load_img(img_path)\n",
        "np.argmax(model.predict(img))  # Make a prediction using the trained model.\n",
        "\n",
        "img = np.expand_dims(cv2.resize(cv2.imread(img_path), (100, 100)), axis=0)\n",
        "img_features = VGG.predict(preprocess_input(img)).reshape(1, 4608)\n",
        "prediction = np.argmax(model.predict(img_features))\n",
        "\n",
        "# Convert the predicted class back to its original label\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "predicted_label = label_encoder.inverse_transform([prediction])[0]\n",
        "encoded_y_train = label_encoder.transform(y_train)\n",
        "encoded_y_test = label_encoder.transform(y_test)\n",
        "\n",
        "#predicted_label = np.argmax(prediction)\n",
        "predicted_class = list_train[predicted_label]\n",
        "\n",
        "# Print the predicted class\n",
        "\n",
        "def openImage():\n",
        "    im = PILImageHandler.open(f\"{img_path}\")\n",
        "    im.show()\n",
        "\n",
        "root = Tk()\n",
        "frm = ttk.Frame(root, padding=20)\n",
        "frm.grid()\n",
        "ttk.Label(frm, text=f\"The predicted class for {img_path} is {list_train[predicted_label]}\").grid(column=0, row=0)\n",
        "ttk.Button(frm, text=\"See image\", command=openImage).grid(column=1, row=0)\n",
        "root.mainloop()\n",
        "\n",
        "print(f\"The predicted class for {img_path} is {list_train[predicted_label]}\")"
      ],
      "metadata": {
        "id": "zdfs5FTKdKsK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}